# chatbot-memoire

Voici un chatbot intelligent liÃ© Ã  un mÃ©moire de fin d'Ã©tudes effectuÃ© au sein de Smart Automation Technologies

\# ğŸ“ Chatbot de Recherche AcadÃ©mique - Assistant IA pour MÃ©moire



\[!\[Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge\&logo=Streamlit\&logoColor=white)](https://streamlit.io/)

\[!\[LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge\&logo=chainlink\&logoColor=white)](https://www.langchain.com/)

\[!\[Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?style=for-the-badge\&logo=huggingface\&logoColor=black)](https://huggingface.co/)

\[!\[Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge\&logo=python\&logoColor=white)](https://www.python.org/)



\## ğŸ“– Description



Assistant IA intelligent conÃ§u pour interroger et explorer un mÃ©moire de fin d'Ã©tudes en Data Science. Ce chatbot utilise des techniques de \*\*Retrieval Augmented Generation (RAG)\*\* pour rÃ©pondre Ã  des questions acadÃ©miques de maniÃ¨re prÃ©cise et contextuelle.



\### ğŸ¯ Projet de Recherche



\*\*Titre du mÃ©moire :\*\*  

\*"Approches intelligentes et mathÃ©matiques pour analyser le churn client dans le e-commerce"\*



\*\*Niveau :\*\* Master en ModÃ©lisation MathÃ©matique et Science de DonnÃ©es



\*\*Domaines couverts :\*\*

\- ModÃ¨les de survie (CoxPH, Weibull AFT, DeepSurv, DeepHit)

\- Analyse du churn client

\- Machine Learning et Deep Learning appliquÃ©s au e-commerce

\- Feature engineering et analyse temporelle



---



\## ğŸš€ Technologies UtilisÃ©es



| Composant | Technologie | RÃ´le |

|-----------|------------|------|

| \*\*LLM\*\* | Mistral-7B-Instruct-v0.2 | GÃ©nÃ©ration de rÃ©ponses |

| \*\*Embeddings\*\* | all-MiniLM-L6-v2 | Vectorisation du texte |

| \*\*Vector Store\*\* | FAISS | Recherche sÃ©mantique |

| \*\*Orchestration\*\* | LangChain | Pipeline RAG |

| \*\*Interface\*\* | Streamlit | Interface utilisateur |

| \*\*HÃ©bergement\*\* | Streamlit Cloud | DÃ©ploiement gratuit |



âœ… \*\*100% Open-Source et Gratuit\*\*



---



\## ğŸ“‚ Structure du Projet



```

chatbot-memoire/

â”‚

â”œâ”€â”€ chatbot\_memoire.py       # Application Streamlit principale

â”œâ”€â”€ requirements.txt          # DÃ©pendances Python

â”œâ”€â”€ README.md                 # Documentation (ce fichier)

â”œâ”€â”€ .env.example              # Template de configuration

â”œâ”€â”€ .gitignore                # Fichiers Ã  ignorer

â”‚

â”œâ”€â”€ data/

â”‚   â””â”€â”€ memoire.pdf           # MÃ©moire de recherche (Ã  ajouter)

â”‚

â””â”€â”€ vector\_store/

&nbsp;   â””â”€â”€ faiss\_index/          # Base vectorielle (auto-gÃ©nÃ©rÃ©e)

```



---



\## âš™ï¸ Installation et ExÃ©cution Locale



\### PrÃ©requis



\- Python 3.9 ou supÃ©rieur

\- pip

\- Un compte Hugging Face (gratuit)



\### Ã‰tapes d'installation



1\. \*\*Cloner le dÃ©pÃ´t\*\*

```bash

git clone https://github.com/votre-username/chatbot-memoire.git

cd chatbot-memoire

```



2\. \*\*CrÃ©er un environnement virtuel\*\* (recommandÃ©)

```bash

python -m venv venv

source venv/bin/activate  # Sur Windows : venv\\Scripts\\activate

```



3\. \*\*Installer les dÃ©pendances\*\*

```bash

pip install -r requirements.txt

```



4\. \*\*Configurer le token Hugging Face\*\*



&nbsp;  a. CrÃ©ez un compte sur \[Hugging Face](https://huggingface.co/)

&nbsp;  

&nbsp;  b. GÃ©nÃ©rez un token : \[Settings > Access Tokens](https://huggingface.co/settings/tokens)

&nbsp;  

&nbsp;  c. Copiez `.env.example` en `.env` :

&nbsp;  ```bash

&nbsp;  cp .env.example .env

&nbsp;  ```

&nbsp;  

&nbsp;  d. Ã‰ditez `.env` et ajoutez votre token :

&nbsp;  ```

&nbsp;  HUGGINGFACE\_API\_TOKEN=hf\_votre\_token\_ici

&nbsp;  ```



5\. \*\*Ajouter votre mÃ©moire\*\*



&nbsp;  Placez votre fichier PDF dans `data/memoire.pdf`



6\. \*\*Lancer l'application\*\*

```bash

streamlit run chatbot\_memoire.py

```



L'application s'ouvrira automatiquement dans votre navigateur Ã  `http://localhost:8501`



---



\## â˜ï¸ DÃ©ploiement sur Streamlit Cloud



\### 1. PrÃ©parer le dÃ©pÃ´t GitHub



\- Assurez-vous que `.env` est dans `.gitignore` (ne jamais commit le token !)

\- Poussez votre code sur GitHub :



```bash

git add .

git commit -m "Initial commit"

git push origin main

```



\### 2. DÃ©ployer sur Streamlit Cloud



1\. Allez sur \[share.streamlit.io](https://share.streamlit.io/)

2\. Cliquez sur \*\*"New app"\*\*

3\. SÃ©lectionnez votre dÃ©pÃ´t GitHub

4\. Configurez :

&nbsp;  - \*\*Main file path:\*\* `chatbot\_memoire.py`

&nbsp;  - \*\*Python version:\*\* 3.9+



\### 3. Ajouter le token en secret



Dans les paramÃ¨tres de l'app Streamlit Cloud :



1\. Allez dans \*\*"Advanced settings"\*\* â†’ \*\*"Secrets"\*\*

2\. Ajoutez :

```toml

HUGGINGFACE\_API\_TOKEN = "hf\_votre\_token\_ici"

```



\### 4. Ajouter le fichier PDF



âš ï¸ \*\*Important :\*\* Le fichier PDF doit Ãªtre dans le dÃ©pÃ´t GitHub dans `data/memoire.pdf`



> \*\*Note :\*\* Si votre mÃ©moire est confidentiel, ne le publiez pas publiquement. Utilisez un dÃ©pÃ´t privÃ© ou dÃ©ployez uniquement localement.



---



\## ğŸ¯ FonctionnalitÃ©s



\### âœ¨ CaractÃ©ristiques principales



\- ğŸ¤– \*\*RÃ©ponses contextuelles\*\* basÃ©es sur le contenu du mÃ©moire

\- ğŸ” \*\*Recherche sÃ©mantique\*\* via embeddings et FAISS

\- ğŸ“š \*\*Citations des sources\*\* avec numÃ©ros de pages

\- âš¡ \*\*Performance optimisÃ©e\*\* avec cache Streamlit

\- ğŸ¨ \*\*Interface intuitive\*\* et responsive

\- ğŸ”’ \*\*Gestion sÃ©curisÃ©e\*\* des tokens API



\### ğŸ’¬ Exemples de questions



```

\- Quels sont les modÃ¨les de survie utilisÃ©s dans ce mÃ©moire ?

\- Explique le modÃ¨le DeepSurv et ses avantages

\- Quelles sont les principales mÃ©triques d'Ã©valuation ?

\- Comment le feature engineering a-t-il Ã©tÃ© rÃ©alisÃ© ?

\- RÃ©sume les conclusions du mÃ©moire

```



---



\## ğŸ› ï¸ Architecture Technique



\### Pipeline RAG



```mermaid

graph LR

&nbsp;   A\[Question] --> B\[Embeddings]

&nbsp;   B --> C\[FAISS Search]

&nbsp;   C --> D\[Top-K Documents]

&nbsp;   D --> E\[LLM Mistral-7B]

&nbsp;   E --> F\[RÃ©ponse]

```



\### Composants clÃ©s



1\. \*\*Chargement du PDF\*\* : PyPDFLoader

2\. \*\*DÃ©coupage\*\* : RecursiveCharacterTextSplitter (1000 tokens, overlap 200)

3\. \*\*Vectorisation\*\* : SentenceTransformers

4\. \*\*Indexation\*\* : FAISS (Similarity Search)

5\. \*\*GÃ©nÃ©ration\*\* : Mistral-7B via Hugging Face API

6\. \*\*Orchestration\*\* : LangChain RetrievalQA



---



\## ğŸ“Š Configuration AvancÃ©e



\### Personnalisation du modÃ¨le



Dans `chatbot\_memoire.py`, modifiez :



```python

\# Changer le LLM

LLM\_MODEL = "HuggingFaceH4/zephyr-7b-alpha"



\# Ajuster les paramÃ¨tres

CHUNK\_SIZE = 800

CHUNK\_OVERLAP = 150

```



\### Optimisation de la recherche



```python

\# Dans create\_qa\_chain()

retriever=vector\_store.as\_retriever(

&nbsp;   search\_type="mmr",  # Maximum Marginal Relevance

&nbsp;   search\_kwargs={"k": 5, "fetch\_k": 10}

)

```



---



\## ğŸ› RÃ©solution de ProblÃ¨mes



\### Erreur : "Token Hugging Face manquant"

\- VÃ©rifiez que `.env` existe et contient `HUGGINGFACE\_API\_TOKEN`

\- Sur Streamlit Cloud, vÃ©rifiez les Secrets



\### Erreur : "Fichier PDF introuvable"

\- Assurez-vous que `data/memoire.pdf` existe

\- VÃ©rifiez le chemin relatif



\### Lenteur de l'application

\- La premiÃ¨re exÃ©cution crÃ©e la base vectorielle (normal)

\- Les suivantes utilisent le cache FAISS



\### Erreur FAISS

```bash

\# Sur certains systÃ¨mes, utilisez faiss-gpu si disponible

pip install faiss-gpu

```



---



\## ğŸ¤ Contribution



Les contributions sont les bienvenues ! Pour contribuer :



1\. Fork le projet

2\. CrÃ©ez une branche (`git checkout -b feature/amelioration`)

3\. Commit vos changements (`git commit -m 'Ajout fonctionnalitÃ©'`)

4\. Push (`git push origin feature/amelioration`)

5\. Ouvrez une Pull Request



---



\## ğŸ“ Licence



Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.



---



\## ğŸ‘¨â€ğŸ“ Auteur



\*\*Projet acadÃ©mique\*\* - Master ModÃ©lisation MathÃ©matique et Science de DonnÃ©es



ğŸ“§ Contact : \[votre-email@exemple.com]  

ğŸ”— LinkedIn : \[Votre profil]  

ğŸ™ GitHub : \[votre-username]



---



\## ğŸ™ Remerciements



\- \[LangChain](https://www.langchain.com/) - Framework d'orchestration

\- \[Hugging Face](https://huggingface.co/) - ModÃ¨les open-source

\- \[Streamlit](https://streamlit.io/) - Interface utilisateur

\- \[FAISS](https://github.com/facebookresearch/faiss) - Recherche vectorielle



---



\## ğŸ“š Ressources SupplÃ©mentaires



\- \[Documentation LangChain](https://python.langchain.com/)

\- \[Guide RAG](https://www.langchain.com/rag)

\- \[Tutoriel Streamlit](https://docs.streamlit.io/)

\- \[Hugging Face Inference API](https://huggingface.co/docs/api-inference/)



---



<div align="center">



\*\*â­ Si ce projet vous a aidÃ©, n'oubliez pas de lui donner une Ã©toile sur GitHub ! â­\*\*



Made with â¤ï¸ and ğŸ¤–



</div>



